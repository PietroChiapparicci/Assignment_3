{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1732181925083,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "NZLKEFGqpkza"
   },
   "outputs": [],
   "source": [
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kMDITdMpkzc"
   },
   "source": [
    "# Map Reduce\n",
    "\n",
    "In the part of the assignment you are requested to use Map Reduce paradigm to solve the following exercises.\n",
    "\n",
    "**NOTE THAT**: **A solution that does not use map reduce is not valid!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UvFKq5Dpkzd"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "You have a list of dictionaries, each representing a student with the following properties: a name and an array of test scores. Your task is to use map, filter, and reduce to calculate the average test score for each student, and then return a list of dictionaries containing only the students whose average score is above 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnZxeOdtpkze"
   },
   "outputs": [],
   "source": [
    "students = [\n",
    "    {\"name\": \"Alice\", \"scores\": [95, 92, 88, 100]},\n",
    "    {\"name\": \"Bob\", \"scores\": [78, 81, 85, 80]},\n",
    "    {\"name\": \"Charlie\", \"scores\": [99, 91, 94, 96]},\n",
    "    {\"name\": \"Diana\", \"scores\": [85, 87, 89, 83]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WopOVxHSpkzf"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGYCqweYpkzf",
    "outputId": "89230ab4-a15a-4ae5-84a3-9eb13573a4a0"
   },
   "outputs": [],
   "source": [
    "[\n",
    "    {\"name\": \"Alice\", \"average_score\": 93.75},\n",
    "    {\"name\": \"Charlie\", \"average_score\": 95.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG5h3pN1pkzg"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1732181928585,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "3ZB3sFT_pkzh",
    "outputId": "cf486e14-4d6f-455d-8f69-19096dfe9831"
   },
   "outputs": [],
   "source": [
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "random_student_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHi3FLeWpkzi"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "import functools\n",
    "def avr(students):\n",
    "    average=functools.reduce(lambda x,y:x+y,students[\"scores\"])/len(students[\"scores\"])\n",
    "    return {\"name\":students[\"name\"],\"average_score\":average }\n",
    "averages=list(map(avr,students))\n",
    "high_avr=list(filter(lambda x:x[\"average_score\"]>90,averages))\n",
    "high_avr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWL_3xWNpkzj"
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "You have a list of dictionaries, each representing a product with the following properties: name, price, and category. Using the functions `map`, `filter`, and `reduce`, calculate the average price of the products in each category and return a list of dictionaries containing only the categories where the average price exceeds 50.\n",
    "\n",
    "Example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwk7f8Ihpkzk"
   },
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"name\": \"Product A\", \"price\": 60, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product B\", \"price\": 40, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product C\", \"price\": 70, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product D\", \"price\": 30, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product E\", \"price\": 90, \"category\": \"Sports\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agz3cP7Ppkzl"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbFtUV_apkzl",
    "outputId": "745cdcbe-7320-4a08-de7b-0e1bcb84473e"
   },
   "outputs": [],
   "source": [
    "[\n",
    "    {\"category\": \"Electronics\", \"average_price\": 50.0},\n",
    "    {\"category\": \"Sports\", \"average_price\": 90.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKBEAQE3pkzl"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1732181933353,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "0qj_9nZSpkzm",
    "outputId": "7bab35c7-84d0-4603-a1da-dc4a76768179"
   },
   "outputs": [],
   "source": [
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "# Example of using the function\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "random_dataset[:5]  # Display the first 5 entries to check the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG9V3Wt7pkzm"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group products by category (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average price for each category and filter categories with an average price > 50\n",
    "temp_dict={}\n",
    "for i in products:\n",
    "    cat=i[\"category\"]\n",
    "    if cat not in temp_dict:\n",
    "        temp_dict[cat]=[]\n",
    "    temp_dict[cat].append(i[\"price\"]) \n",
    "grouped_prod=[]\n",
    "for cat,prices in temp_dict.items():\n",
    "    temp_dict2={\"category\":cat,\"prices\":prices}\n",
    "    grouped_prod.append(temp_dict2)\n",
    "\n",
    "def avr(grouped_prod):\n",
    "    average=functools.reduce(lambda x,y:x+y,grouped_prod[\"prices\"])/len(grouped_prod[\"prices\"])\n",
    "    return {\"category\":grouped_prod[\"category\"],\"average_price\":average }\n",
    "averages=list(map(avr,grouped_prod))\n",
    "high_avr=list(filter(lambda x:x[\"average_price\"]>50,averages))\n",
    "high_avr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hivtZEf7pkzm"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "You have a list of dictionaries, each representing an employee with the following properties: name, salary, and department. Your task is to use `map`, `filter`, and `reduce` to calculate the average salary for each department and return a list of dictionaries containing only the departments where the average salary is above 65,000.\n",
    "\n",
    "**Example Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1732181936402,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "N8vjLRHxpkzm"
   },
   "outputs": [],
   "source": [
    "employees = [\n",
    "    {\"name\": \"John\", \"salary\": 70000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Jane\", \"salary\": 75000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Alice\", \"salary\": 60000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Bob\", \"salary\": 68000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Charlie\", \"salary\": 90000, \"department\": \"Marketing\"},\n",
    "    {\"name\": \"Diana\", \"salary\": 50000, \"department\": \"Marketing\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otSniMO7pkzm"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx4HT8RXpkzn",
    "outputId": "8653ff13-815d-4040-c68e-fc4a6825134d"
   },
   "outputs": [],
   "source": [
    "[\n",
    "    {\"department\": \"Engineering\", \"average_salary\": 72500.0},\n",
    "    {\"department\": \"Marketing\", \"average_salary\": 70000.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD_xlB78pkzn"
   },
   "source": [
    "### Test\n",
    "\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1732181939215,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "RhR9JLK-pkzn",
    "outputId": "72bc934d-4d3c-477e-cf84-3cf1d8fae61a"
   },
   "outputs": [],
   "source": [
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_employee_dataset = generate_random_employee_dataset(50)\n",
    "\n",
    "random_employee_dataset[:3]  # Display the first 3 entries of each dataset for checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt9m6NK-pkzo"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "temp_dict={}\n",
    "for i in employees:\n",
    "    cat=i[\"department\"]\n",
    "    if cat not in temp_dict:\n",
    "        temp_dict[cat]=[]\n",
    "    temp_dict[cat].append(i[\"salary\"]) \n",
    "grouped_prod=[]\n",
    "for cat, salaries in temp_dict.items():\n",
    "    temp_dict2={\"department\":cat,\"salaries\":salaries}\n",
    "    grouped_prod.append(temp_dict2)\n",
    "\n",
    "def avr(grouped_prod):\n",
    "    average=functools.reduce(lambda x,y:x+y,grouped_prod[\"salaries\"])/len(grouped_prod[\"salaries\"])\n",
    "    return {\"department\":grouped_prod[\"department\"],\"average_salary\":average }\n",
    "averages=list(map(avr,grouped_prod))\n",
    "high_avr=list(filter(lambda x:x[\"average_salary\"]>65000,averages))\n",
    "print(high_avr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzxr0v2Rpkzo"
   },
   "source": [
    "# Biopython\n",
    "\n",
    "Write the following five functions to analyze global alignments between two sequences using Biopython's `pairwise2` module:\n",
    "\n",
    "1. **countMatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment (pairwise2.globalxx) of the same length. It returns the number of positions where the elements of both sequences match.\n",
    "\n",
    "2. **countMismatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of positions where the elements of the two sequences are different (i.e., they are not gaps, and the characters do not match).\n",
    "\n",
    "3. **countGapOpens(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap openings in the alignment (a gap is opened when a '-' appears in the sequence).\n",
    "\n",
    "4. **countGapExtensions(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap extensions (where '-' continues in the alignment after an initial gap is opened).\n",
    "\n",
    "5. **getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment and returns the alignment score based on the provided scoring scheme: `matchScore` for matches, `mismatchPenalty` for mismatches, `gapOpenPenalty` for opening a gap, and `gapExtensionPenalty` for extending a gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your functions here\n",
    "from Bio import pairwise2\n",
    "from Bio import SeqIO\n",
    "def parse_fasta(file):\n",
    "    dna_data1=[]\n",
    "    for record in SeqIO.parse(file, \"fasta\"): #file has to be present in the same folder as this file\n",
    "        sequence=str(record.seq)\n",
    "        dna_data1.append(sequence)\n",
    "    return dna_data1\n",
    "s1=parse_fasta('IL12A.fasta')\n",
    "s2=parse_fasta('IL12B.fasta')\n",
    "s1=''.join(s1)\n",
    "s2=''.join(s2)\n",
    "alignement=pairwise2.align.globalxx(s1,s2)\n",
    "\n",
    "def countMatches(new_s1,new_s2):\n",
    "    counter=0\n",
    "    for i,z in zip(new_s1,new_s2):\n",
    "        if i==z:\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def countMismatches(new_s1,new_s2):\n",
    "    counter=0\n",
    "    for i,z in zip(new_s1,new_s2):\n",
    "        if i!='-' and z!='-' and i!=z:\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def countGapOpens(new_s1,new_s2):\n",
    "    counter=0\n",
    "    n=len(new_s1)\n",
    "    for i in range(n):\n",
    "        if new_s1[i]=='-'and (i==0 or new_s1[i-1]!='-'):\n",
    "            counter+=1\n",
    "        if new_s2[i]=='-'and (i==0 or new_s2[i-1]!='-'):\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def countGapExtensions(new_s1,new_s2):\n",
    "    counter=0\n",
    "    n=len(new_s1)\n",
    "    for i in range(1,n):\n",
    "        if new_s1[i]=='-'and new_s1[i-1]=='-':\n",
    "            counter+=1\n",
    "        if new_s2[i]=='-' and new_s2[i-1]=='-':\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def getScore(alignement,matchScore,mismatchPenalty,gapOpenPenalty,gapExtensionPenalty):\n",
    "        highest_score=float('-inf')\n",
    "        best_alignement=-1\n",
    "        for pos,i in enumerate(alignement):\n",
    "                FinalScore=0\n",
    "                new_s1=i[0]\n",
    "                new_s2=i[1]\n",
    "                a=countMatches(new_s1,new_s2)\n",
    "                b=countMismatches(new_s1,new_s2)\n",
    "                c=countGapOpens(new_s1,new_s2)\n",
    "                d=countGapExtensions(new_s1,new_s2)\n",
    "                FinalScore=(matchScore*a)+(mismatchPenalty*b)+(gapOpenPenalty*c)+(gapExtensionPenalty*d)\n",
    "                if FinalScore>highest_score:\n",
    "                        highest_score=FinalScore\n",
    "                        best_alignement=pos\n",
    "        return countMatches(alignement[best_alignement][0],alignement[best_alignement][1]),countMismatches(alignement[best_alignement][0],alignement[best_alignement][1]), countGapOpens(alignement[best_alignement][0],alignement[best_alignement][1]), countGapExtensions(alignement[best_alignement][0],alignement[best_alignement][1]), highest_score, best_alignement\n",
    "                            \n",
    "\n",
    "#Score and penalty values can be chosen arbitrarily\n",
    "matchScore=1\n",
    "mismatchPenalty=0\n",
    "gapOpenPenalty=0\n",
    "gapExtensionPenalty=0\n",
    "final_result=getScore(alignement,matchScore,mismatchPenalty,gapOpenPenalty,gapExtensionPenalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81O19v1fpkzo"
   },
   "source": [
    "### Test\n",
    "Align the sequences of the [Interleukin-12](https://en.wikipedia.org/wiki/Interleukin_12) chain A (denoted as `s1`) from the file [`IL12A.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12A.fasta) and the Interleukin-12 chain B (denoted as `s2`) from the file [`IL12B.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12B.fasta) and check the score as computed from pairwise2 and from your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBhfr3jepkzp"
   },
   "outputs": [],
   "source": [
    "# add the output of the test here\n",
    "print(f'Score value has been calculated using the following point system:\\n{matchScore} point(s) for matches,\\n{mismatchPenalty} point(s) for mismatches,\\n{gapOpenPenalty} point(s) for opening a gap,\\n{gapExtensionPenalty} point(s) for extending a gap\\n')\n",
    "print(f'The output of each function for the alignement with the highest final score (alignment number {final_result[5]}) are:\\ncountMatches result:{final_result[0]},\\ncountMismatches result: {final_result[1]},\\ncountGapOpens result: {final_result[2]},\\ncountGapExtensions result: {final_result[3]},\\nfinal score: {final_result[4]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rosalind exercises\n",
    "\n",
    "The following cells contain functions to solve the assigned Rosalind problems:\n",
    "\n",
    "1. **lgis**  \n",
    "   \n",
    "2. **sseq**  \n",
    "\n",
    "3. **lcsq**  \n",
    "\n",
    "4. **edit**  \n",
    "   \n",
    "6. **edta**  \n",
    "\n",
    "7. **ctea**  \n",
    "\n",
    "8. **glob**  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)lgis\n",
    "\n",
    "with open('rosalind_lgis.txt','r') as file:\n",
    "    n=int(file.readline().strip())\n",
    "    pi=list(map(int, file.readline().strip().split()))\n",
    "\n",
    "def longest_incr_subseq(pi):\n",
    "    n=len(pi)\n",
    "    dp=[1]*n\n",
    "    tracker=[-1]*n\n",
    "    for i in range(1,n):\n",
    "        for j in range(i):\n",
    "            if pi[i]>pi[j] and dp[i]<dp[j]+1:\n",
    "                dp[i]=dp[j]+1\n",
    "                tracker[i]=j\n",
    "    max_len=max(dp)\n",
    "    idx=dp.index(max_len)\n",
    "    lis=[]\n",
    "    while idx!=-1:\n",
    "        lis.append(pi[idx])\n",
    "        idx=tracker[idx]\n",
    "    \n",
    "    return lis[::-1]\n",
    "\n",
    "lis=longest_incr_subseq(pi)\n",
    "\n",
    "\n",
    "def longest_decr_subseq(pi):\n",
    "    return longest_incr_subseq(pi[::-1])[::-1] #the longest decreasing subsequence is the longest increasing \n",
    "lds=longest_decr_subseq(pi)                    #subsequence of the inverted sequence\n",
    "\n",
    "\n",
    "print(\" \".join(map(str,lis)))\n",
    "print(\" \".join(map(str,lds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)sseq\n",
    "\n",
    "from Bio import SeqIO\n",
    "def parse_fasta():\n",
    "    dna_data=[]\n",
    "    for record in SeqIO.parse(\"rosalind_sseq.txt\",\"fasta\"): #rosalind dataset has to be present in the same folder as this file\n",
    "        sequence=str(record.seq)\n",
    "        dna_data.append(sequence)\n",
    "    return dna_data\n",
    "dna_data=parse_fasta()\n",
    "\n",
    "def sseq(dna_data):\n",
    "    s=dna_data[0]\n",
    "    t=dna_data[1]\n",
    "    idx_collection=[]\n",
    "    tracker=0\n",
    "    for z in t:\n",
    "        for i in range(tracker,len(s)):\n",
    "            if z==s[i]:\n",
    "                idx_collection.append(i+1)\n",
    "                tracker=i+1\n",
    "                break\n",
    "    return idx_collection\n",
    "\n",
    "result=sseq(dna_data)\n",
    "result=' '.join(map(str,result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)lcsq\n",
    "\n",
    "from Bio import SeqIO\n",
    "def parse_fasta():\n",
    "    dna_data=[]\n",
    "    for record in SeqIO.parse(\"rosalind_lcsq.txt\",\"fasta\"): #rosalind dataset has to be present in the same folder as this file\n",
    "        sequence=str(record.seq)\n",
    "        dna_data.append(sequence)\n",
    "    return dna_data\n",
    "dna_data=parse_fasta()\n",
    "\n",
    "def lcsq(dna_data):\n",
    "    s=dna_data[0]\n",
    "    m=len(s)\n",
    "    t=dna_data[1]\n",
    "    n=len(t)\n",
    "    long_subseq=[]\n",
    "    dp=[]\n",
    "    for i in range(m+1):\n",
    "        dp.append([0]*(n+1))\n",
    "    for i in range(1,m+1):\n",
    "            for j in range(1,n+1):\n",
    "                if s[i-1]==t[j-1]:\n",
    "                    dp[i][j]=dp[i-1][j-1]+1\n",
    "                else:\n",
    "                    dp[i][j]=max(dp[i-1][j],dp[i][j-1])\n",
    "    i=m\n",
    "    j=n\n",
    "    while i>0 and j>0:\n",
    "            if s[i-1]==t[j-1]:\n",
    "                long_subseq.append(s[i-1])\n",
    "                i-=1\n",
    "                j-=1\n",
    "            elif dp[i-1][j]>dp[i][j-1]:\n",
    "                i-=1\n",
    "            else:\n",
    "                j-=1\n",
    "    return ''.join(reversed(long_subseq))\n",
    "\n",
    "result=lcsq(dna_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)edit\n",
    "\n",
    "from Bio import SeqIO\n",
    "def parse_fasta():\n",
    "    dna_data=[]\n",
    "    for record in SeqIO.parse(\"rosalind_edit.txt\",\"fasta\"): #rosalind dataset has to be present in the same folder as this file\n",
    "        sequence=str(record.seq)\n",
    "        dna_data.append(sequence)\n",
    "    return dna_data\n",
    "dna_data=parse_fasta()\n",
    "\n",
    "def edit(dna_data):\n",
    "    s=dna_data[0]\n",
    "    t=dna_data[1]\n",
    "    m=len(s)\n",
    "    n=len(t)\n",
    "    dp=[]\n",
    "    for i in range(m+1):\n",
    "        dp.append([0]*(n+1))\n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i==0:\n",
    "                dp[i][j]=j\n",
    "            elif j==0:\n",
    "                dp[i][j]=i\n",
    "            elif s[i-1]==t[j-1]:\n",
    "                dp[i][j]=dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j]=1+min(dp[i-1][j],dp[i][j-1],dp[i-1][j-1])\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "result=edit(dna_data)\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)edta\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "def parse_fasta():\n",
    "    dna_data=[]\n",
    "    for record in SeqIO.parse(\"rosalind_edta.txt\",\"fasta\"):\n",
    "        sequence=str(record.seq)\n",
    "        dna_data.append(sequence)\n",
    "    return dna_data\n",
    "\n",
    "def edta(dna_data):\n",
    "    s=dna_data[0]\n",
    "    t=dna_data[1]\n",
    "    m=len(s)\n",
    "    n=len(t)\n",
    "    dp=[]\n",
    "    for i in range(m+1):\n",
    "        dp.append([0]*(n+1))\n",
    "    for i in range(m+1):\n",
    "        dp[i][0]=i\n",
    "    for j in range(n+1):\n",
    "        dp[0][j]=j\n",
    "    \n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            if s[i-1]==t[j-1]:\n",
    "                dp[i][j]=dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j]=1+min(dp[i-1][j],dp[i][j-1],dp[i-1][j-1])\n",
    "    i= m\n",
    "    j=n\n",
    "    new_s=[]\n",
    "    new_t=[]\n",
    "    \n",
    "    while i>0 or j>0:\n",
    "        if i>0 and j>0 and s[i-1]==t[j-1]:\n",
    "            new_s.append(s[i-1])\n",
    "            new_t.append(t[j-1])\n",
    "            i-=1\n",
    "            j-=1\n",
    "        elif i>0 and dp[i][j]==dp[i-1][j]+1:\n",
    "            new_s.append(s[i-1])\n",
    "            new_t.append('-')\n",
    "            i-=1\n",
    "        elif j>0 and dp[i][j]==dp[i][j-1]+1:\n",
    "            new_s.append('-')\n",
    "            new_t.append(t[j-1])\n",
    "            j-=1\n",
    "        else:\n",
    "            new_s.append(s[i - 1])\n",
    "            new_t.append(t[j - 1])\n",
    "            i-=1\n",
    "            j-=1\n",
    "    new_s.reverse()\n",
    "    new_t.reverse()\n",
    "    new_s=''.join(new_s)\n",
    "    new_t=''.join(new_t)\n",
    "    edit_distance = dp[m][n]\n",
    "    \n",
    "    return edit_distance,new_s,new_t\n",
    "\n",
    "dna_data=parse_fasta()\n",
    "result1,result2,result3=edta(dna_data)\n",
    "print(result1)\n",
    "print(result2)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6)ctea\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "def parse_fasta():\n",
    "    dna_data=[]\n",
    "    for record in SeqIO.parse(\"rosalind_ctea.txt\",\"fasta\"):\n",
    "        sequence=str(record.seq)\n",
    "        dna_data.append(sequence)\n",
    "    return dna_data\n",
    "dna_data=parse_fasta()\n",
    "\n",
    "def ctea(dna_data):\n",
    "    mod=134217727\n",
    "    s=dna_data[0]\n",
    "    t=dna_data[1]\n",
    "    m=len(s)\n",
    "    n=len(t)\n",
    "    E=[]\n",
    "    for i in range(m+1):\n",
    "        E.append([0]*(n+1))\n",
    "    O=[]\n",
    "    for i in range(m+1):\n",
    "        O.append([0]*(n+1))\n",
    "\n",
    "    for i in range(m+1):\n",
    "        E[i][0]=i\n",
    "        O[i][0]=1\n",
    "    for j in range(n+1):\n",
    "        E[0][j]=j\n",
    "        O[0][j]=1\n",
    "\n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            if s[i-1]==t[j-1]:\n",
    "                match_cost=0\n",
    "            else:\n",
    "                match_cost=1\n",
    "            delt=E[i-1][j]+1\n",
    "            insr=E[i][j-1]+1\n",
    "            subs=E[i-1][j-1]+match_cost\n",
    "            E[i][j]=min(delt,insr,subs)\n",
    "            if E[i][j]==delt:\n",
    "                O[i][j]+=O[i-1][j]\n",
    "            if E[i][j]==insr:\n",
    "                O[i][j]+= O[i][j-1]\n",
    "            if E[i][j]==subs:\n",
    "                O[i][j]+=O[i-1][j-1]\n",
    "\n",
    "            O[i][j]%=mod\n",
    "\n",
    "    return O[m][n]\n",
    "\n",
    "\n",
    "result=ctea(dna_data)\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7)glob\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "def parse_fasta():\n",
    "    dna_data=[]\n",
    "    for record in SeqIO.parse(\"rosalind_glob.txt\",\"fasta\"):\n",
    "        sequence=str(record.seq)\n",
    "        dna_data.append(sequence)\n",
    "    return dna_data\n",
    "dna_data=parse_fasta()\n",
    "\n",
    "BLOSUM62={\n",
    "    'A': {'A': 4, 'C': 0, 'D': -2, 'E': -1, 'F': -2, 'G': 0, 'H': -2, 'I': -1, 'K': -1, 'L': -1, \n",
    "          'M': -1, 'N': -2, 'P': -1, 'Q': -1, 'R': -1, 'S': 1, 'T': 0, 'V': 0, 'W': -3, 'Y': -2},\n",
    "    'C': {'A': 0, 'C': 9, 'D': -3, 'E': -4, 'F': -2, 'G': -3, 'H': -3, 'I': -1, 'K': -3, 'L': -1, \n",
    "          'M': -1, 'N': -3, 'P': -3, 'Q': -3, 'R': -3, 'S': -1, 'T': -1, 'V': -1, 'W': -2, 'Y': -2},\n",
    "    'D': {'A': -2, 'C': -3, 'D': 6, 'E': 2, 'F': -3, 'G': -1, 'H': -1, 'I': -3, 'K': -1, 'L': -4, \n",
    "          'M': -3, 'N': 1, 'P': -1, 'Q': 0, 'R': -2, 'S': 0, 'T': -1, 'V': -3, 'W': -4, 'Y': -3},\n",
    "    'E': {'A': -1, 'C': -4, 'D': 2, 'E': 5, 'F': -3, 'G': -2, 'H': 0, 'I': -3, 'K': 1, 'L': -3, \n",
    "          'M': -2, 'N': 0, 'P': -1, 'Q': 2, 'R': 0, 'S': 0, 'T': -1, 'V': -2, 'W': -3, 'Y': -2},\n",
    "    'F': {'A': -2, 'C': -2, 'D': -3, 'E': -3, 'F': 6, 'G': -3, 'H': -1, 'I': 0, 'K': -3, 'L': 0, \n",
    "          'M': 0, 'N': -3, 'P': -4, 'Q': -3, 'R': -3, 'S': -2, 'T': -2, 'V': -1, 'W': 1, 'Y': 3},\n",
    "    'G': {'A': 0, 'C': -3, 'D': -1, 'E': -2, 'F': -3, 'G': 6, 'H': -2, 'I': -4, 'K': -2, 'L': -4, \n",
    "          'M': -3, 'N': 0, 'P': -2, 'Q': -2, 'R': -2, 'S': 0, 'T': -2, 'V': -3, 'W': -2, 'Y': -3},\n",
    "    'H': {'A': -2, 'C': -3, 'D': -1, 'E': 0, 'F': -1, 'G': -2, 'H': 8, 'I': -3, 'K': -1, 'L': -3, \n",
    "          'M': -2, 'N': 1, 'P': -2, 'Q': 0, 'R': 0, 'S': -1, 'T': -2, 'V': -3, 'W': -2, 'Y': 2},\n",
    "    'I': {'A': -1, 'C': -1, 'D': -3, 'E': -3, 'F': 0, 'G': -4, 'H': -3, 'I': 4, 'K': -3, 'L': 2, \n",
    "          'M': 1, 'N': -3, 'P': -3, 'Q': -3, 'R': -3, 'S': -2, 'T': -1, 'V': 3, 'W': -3, 'Y': -1},\n",
    "    'K': {'A': -1, 'C': -3, 'D': -1, 'E': 1, 'F': -3, 'G': -2, 'H': -1, 'I': -3, 'K': 5, 'L': -2, \n",
    "          'M': -1, 'N': 0, 'P': -1, 'Q': 1, 'R': 2, 'S': 0, 'T': -1, 'V': -2, 'W': -3, 'Y': -2},\n",
    "    'L': {'A': -1, 'C': -1, 'D': -4, 'E': -3, 'F': 0, 'G': -4, 'H': -3, 'I': 2, 'K': -2, 'L': 4, \n",
    "          'M': 2, 'N': -3, 'P': -3, 'Q': -2, 'R': -2, 'S': -2, 'T': -1, 'V': 1, 'W': -2, 'Y': -1},\n",
    "    'M': {'A': -1, 'C': -1, 'D': -3, 'E': -2, 'F': 0, 'G': -3, 'H': -2, 'I': 1, 'K': -1, 'L': 2, \n",
    "          'M': 5, 'N': -2, 'P': -2, 'Q': 0, 'R': -1, 'S': -1, 'T': -1, 'V': 1, 'W': -1, 'Y': -1},\n",
    "    'N': {'A': -2, 'C': -3, 'D': 1, 'E': 0, 'F': -3, 'G': 0, 'H': 1, 'I': -3, 'K': 0, 'L': -3, \n",
    "          'M': -2, 'N': 6, 'P': -2, 'Q': 0, 'R': 0, 'S': 1, 'T': 0, 'V': -3, 'W': -4, 'Y': -2},\n",
    "    'P': {'A': -1, 'C': -3, 'D': -1, 'E': -1, 'F': -4, 'G': -2, 'H': -2, 'I': -3, 'K': -1, 'L': -3, \n",
    "          'M': -2, 'N': -2, 'P': 7, 'Q': -1, 'R': -2, 'S': -1, 'T': -1, 'V': -2, 'W': -4, 'Y': -3},\n",
    "    'Q': {'A': -1, 'C': -3, 'D': 0, 'E': 2, 'F': -3, 'G': -2, 'H': 0, 'I': -3, 'K': 1, 'L': -2, \n",
    "          'M': 0, 'N': 0, 'P': -1, 'Q': 5, 'R': 1, 'S': 0, 'T': -1, 'V': -2, 'W': -2, 'Y': -1},\n",
    "    'R': {'A': -1, 'C': -3, 'D': -2, 'E': 0, 'F': -3, 'G': -2, 'H': 0, 'I': -3, 'K': 2, 'L': -2, \n",
    "          'M': -1, 'N': 0, 'P': -2, 'Q': 1, 'R': 5, 'S': -1, 'T': -1, 'V': -3, 'W': -3, 'Y': -2},\n",
    "    'S': {'A': 1, 'C': -1, 'D': 0, 'E': 0, 'F': -2, 'G': 0, 'H': -1, 'I': -2, 'K': 0, 'L': -2, \n",
    "          'M': -1, 'N': 1, 'P': -1, 'Q': 0, 'R': -1, 'S': 4, 'T': 1, 'V': -2, 'W': -3, 'Y': -2},\n",
    "    'T': {'A': 0, 'C': -1, 'D': -1, 'E': -1, 'F': -2, 'G': -2, 'H': -2, 'I': -1, 'K': -1, 'L': -1, \n",
    "          'M': -1, 'N': 0, 'P': -1, 'Q': -1, 'R': -1, 'S': 1, 'T': 5, 'V': 0, 'W': -2, 'Y': -2},\n",
    "    'V': {'A': 0, 'C': -1, 'D': -3, 'E': -2, 'F': -1, 'G': -3, 'H': -3, 'I': 3, 'K': -2, 'L': 1, \n",
    "          'M': 1, 'N': -3, 'P': -2, 'Q': -2, 'R': -3, 'S': -2, 'T': 0, 'V': 4, 'W': -3, 'Y': -1},\n",
    "    'W': {'A': -3, 'C': -2, 'D': -4, 'E': -3, 'F': 1, 'G': -2, 'H': -2, 'I': -3, 'K': -3, 'L': -2, \n",
    "          'M': -1, 'N': -4, 'P': -4, 'Q': -2, 'R': -3, 'S': -3, 'T': -2, 'V': -3, 'W': 11, 'Y': 2},\n",
    "    'Y': {'A': -2, 'C': -2, 'D': -3, 'E': -2, 'F': 3, 'G': -3, 'H': 2, 'I': -1, 'K': -2, 'L': -1, \n",
    "          'M': -1, 'N': -2, 'P': -3, 'Q': -1, 'R': -2, 'S': -2, 'T': -2, 'V': -1, 'W': 2, 'Y': 7},\n",
    "}\n",
    "\n",
    "\n",
    "def glob(dna_data):\n",
    "    s=dna_data[0]\n",
    "    t=dna_data[1]\n",
    "    m=len(s)\n",
    "    n=len(t)\n",
    "    gap_penalty=-5\n",
    "    dp=[]\n",
    "    for i in range(m+1):\n",
    "        dp.append([0]*(n+1))\n",
    "    for i in range(1,m+1):\n",
    "        dp[i][0]=i*gap_penalty\n",
    "    for j in range(1,n+1):\n",
    "        dp[0][j]=j*gap_penalty\n",
    "\n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            match=dp[i-1][j-1]+BLOSUM62[s[i-1]][t[j-1]]\n",
    "            delt=dp[i-1][j]+gap_penalty\n",
    "            insr=dp[i][j-1]+gap_penalty\n",
    "            dp[i][j]=max(match, delt, insr)\n",
    "    \n",
    "    i=m\n",
    "    j=n\n",
    "    new_s=[]\n",
    "    new_t=[]\n",
    "    while i>0 or j>0:\n",
    "        if i>0 and j>0 and dp[i][j]==dp[i-1][j-1]+BLOSUM62[s[i-1]][t[j-1]]:\n",
    "            new_s.append(s[i-1])\n",
    "            new_t.append(t[j-1])\n",
    "            i-=1\n",
    "            j-=1\n",
    "        elif i>0 and dp[i][j]==dp[i-1][j]+gap_penalty:\n",
    "            new_s.append(s[i-1])\n",
    "            new_t.append('-')\n",
    "            i-=1\n",
    "        else:\n",
    "            new_s.append('-')\n",
    "            new_t.append(t[j-1])\n",
    "            j-=1\n",
    "    max_align_score=dp[m][n]\n",
    "    return max_align_score\n",
    "\n",
    "result=glob(dna_data)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
